# 1장. 사용자 수에 따른 규모 확장성

- 단일 서버 : 웹, 앱, 데이터베이스, 캐시 등이 전부 서버 한 대에서 실행됨

### 데이터베이스

- 유저가 늘어서 여러 서버를 두어야 하는 경우, 하나는 `웹/모바일 트래픽 처리 용도`이고, 다른 하나는 `데이터베이스용`이다.
- 데이터 베이스는 관계형 / 비관계형 데이터베이스가 존재하는데, 비관계형 데이터베이스가 바람직한 경우는 다음과 같다.
    - 아주 낮은 응답 지연시간(latency)이 요구됨
    - 다루는 데이터가 비정형(unstructured) 이라 관계형 데이터가 아님
    - 데이터를 직렬화/역직렬화 할 수 있기만 하면 됨
    - 아주 많은 양의 데이터를 저장할 필요가 있음

---

### 수직적 규모 확장 vs. 수평적 규모 확장

- 서버로 유입되는트래픽의 양이 적을 때 ⇒ “수직적 확장”
- 하지만, 수직적 확장은 자동복구 방안 or 다중화 방안을 제시하지 않는다. 서버에 장애가 발생하면 웹사이트/앱은 완전히 중단된다.
- 대규모 애플리케이션을 지원하는 데는 수평적 규모 확장법이 적절
- 웹 서버에 바로 연결될 때 응답 속도가 느려지거나 서버 접속이 불가능해 질 때 부하 분산기 or 로드 밸런서 도입 가능
- 로드밸런서
    
    = 트래픽 부하를 고르게 분산하는 역할 
    
    - 부하 분산 집합에 또 하나의 웹 서버를 추가하고 나면 장애를 자동복구하지 못하는 문제  해소 가능
- 데이터베이스 다중화(데이터 계층)
    - master-slave 관계 설정 → 데이터 원본은 주 서버, 사본은 부 서버에 저장하는 방식
    - master : 쓰기 연산
    - slave : 읽기 연산

✔️ 응답 시간 개선 위해 “캐시”를 붙이고 정적 콘텐츠를 CDN 으로 옮기면 개선할 수 있다.

### 캐시

= 값비싼 연산 결과or자주 참조되는 데이터를 메모리 안에 두고, 요청이 보다 빨리 처리될 수 있도록 하는 저장소

- 애플리케이션의 성능은 ***데이터베이스를 얼마나 자주 호출하느냐***에 따라 좌우된다
- 캐시 계층
    - 캐시 우선 읽기 전략
    - memcached API
- 캐시 사용 시 유의할 점
    - 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어나는 경우
    - **`일관성` :** 데이터 저장소의 원본/캐시 내의 사본이 같은지 여부
        - 저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우 이 일관성은 깨질 수 있다.
    - 캐시 서버를 한 대만 두는 경우 해당 서버의 단일장애지점(SPOF)이 되어버릴 가능성 존재
        
        ⇒ 여러 지역에 걸쳐 캐시 서버를 분산시켜야 함
        
    - 캐시 메모리 과할당(overprovision)
    - 데이터 방출 정책 : LRU, LFU, FIFO

### 콘텐츠 전송 네트워크 (CDN)

= 정적 콘텐츠를 전송하는데 쓰이는 지리적으로 분산된 서버의 네트워크 

- *동적 콘텐츠 캐싱 = 요청 경로, 질의 문자열, 쿠키, 요청 헤더 등의 정보에 기반하여 HTML 페이지를 캐싱*
- 사용자 → 웹사이트 방문 → 사용자에게 가장 가까운 CDN 서버가 정적 컨텐츠를 전달
    
    ⇒ 사용자가 CDN 서버로부터 멂면 멀수록 웹사이트는 천천히 로드됨 
    
- CDN 동작 원리
    1. 이미지 URL을 이용해 image.png에 접근. URL의 도메인은 CDN 서비스 사업자가 제공한 것.
    2. CDN 서버의 캐시에 해당 이미지가 없는 경우 서보는 원본 서버에 요청하여 파일을 가져옴. 
    3. 원본 서버가 파일을 CDN 서버에 반환. HTTP 헤더에는 해당 파일이 얼마나 오래 캐시될 수 있는지를 설명하는 TTL값이 들어가 있음 
    4. CDN 서버는 파일을 캐시, 반환. 이미지는 TTL에 명시된 시간이 끝날때까지 캐시됨
    5. 다른 유저가 같은 이미지에 대한 요청을 CDN 서버에 전송
    6. 만료되지 않은 이미지에 대한 요청은 캐시를 통해 처리됨 

✔️ 정적 콘텐츠는 더 이상 웹 서버를 통해 서비스하지 X, CDN을 통해 제공하여 더 나은 성능을 보장

✔️ 캐시가 데이터베이스 부하를 줄여줌 

![image.png](image.png)

---

### 무상태(stateless) 웹 계층

- 웹 계층을 수평적으로 확장하기 위해서는 **상태 정보(사용자 세션 데이터와 같은)를 웹 계층에서 제거해야 함**
    
    ⇒ 상태 정보는 지속성 저장소에 보관하고 필요할 때 가져오도록 함
    
- ***상태 정보 의존적인 아키텍처***
    - 클라이언트 정보(상태)를 유지하여 요청들 사이에 공유되도록 함
    - 같은 클라이언트로부터의 요청은 항상 같은 서버로 전송되어야 한다는 것
        
        → “고정 세션” : 로드 밸런서에 부담 
        
- ***무상태 아키텍처***
    - HTTP 요청은 어떤 웹 서버로도 전달될 수 있고 웹 서버는 상태 정보가 필요할 경우 “공유 저장소”로부터 데이터를 불러옴
    
    ⇒ 상태 정보는 웹 서버로부터 물리적으로 분리되어 있음
    

---

### 데이터 센터

- 두 개의 데이터 센터. 지리적 라우팅(가장 가까운 데이터 센터로 안내됨)
- 다중 데이터센터 아키텍처를 만들기 위해 해결해야하는 기술적 난제
    - 트래픽 우회 : 올바른 데이터 센터로 트래픽을 보내는 효과적인 방법을 찾아야 함
    - 데이터 동기화 : 데이터를 여러 데이터 센터에 걸쳐 다중화
    - 테스트와 배포 : 자동화된 배포 도구는 모든 데이터 센터에 동일한 서비스가 설치되도록 하는 데 중요한 역할

✔️ 시스템을 더 큰 규모로 확장하기 위해 **시스템의 컴포넌트를 분리+독립적으로 확장할 수 있도록 해야** 

⇒ `“메시지 큐”` 가 이를 해결할 수 있음 

---

### 메시지 큐

> 메시지의 **무손실**(=메시지 큐에 일단 보관된 메시지는 소비자가 꺼낼 때까지 안전히 보관된다는 특성)을 보장하는 **비동기 통신**을 지원하는 컴포넌트
> 
- 메시지의 버퍼 역할, 비동기적으로 전송
- 메시지 큐 사용 시, 서버간 결합이 느슨해짐 → 안정적 애플리케이션 구성하기 좋음
- 생산자는 소비자 프로세스가 다운되어 있어도 메시지를 발행할 수 있고, 소비자는 생산자 서비스가 가용한 상태가 아니어도 메시지 수신 가능
- (ex.)
    1. *웹 서버가 사진 보정 작업(job)을 메시지 큐에 넣음*
    2. *사진 보정 작업(worker) 프로세스들은 이 작업을 메시지 큐에서 꺼내 비동기적으로 완료*

### 로그, 메트릭, 자동화

- `로그`
    - 에러 로그 모니터링
    - 로그를 단일 서비스로 모아주는 도구 활용 가능
- `메트릭` : 메트릭을 잘 수집하면 사업 현황에 관한 유용한 정보를 얻을 수도 있고, 시스템의 현재 상태를 손쉽게 파악 O
    - 호스트 단위 메트릭, 종합 메트릭, 핵심 비즈니스 메트릭
- `자동화` : 코드가 검증 절차를 자동으로 거치도록 할 수 O

![image.png](./image/image.png)

---

### 데이터베이스의 규모 확장

- 수직적 확장 : SPOF로 인한 위험성이 크다
- **수평적 확장(=샤딩)**
    - 샤딩=대규모 데이터베이스를 샤드라고 부르는 작은 단위로 분할
    - 모든 샤드는 같은 스키마를 쓰지만 샤드에 보관되는 데이터 사이에는 중복이 없다.
    - `“샤딩 키(=파티션 키)”` 중요 !
        
        → 데이터가 어떻게 분산될 지 정하는 하나 이상의 칼럼으로구성됨 
        
        - 데이터를 고르게 분할 할 수 있도록 샤딩 키를 정해야 함
    - 해결해야 하는 문제
        - 데이터의 재 샤딩(reshading)
            1. 데이터가 너무 많아져서 하나의 샤드로는 더 이상 감당하기 어려울 때
            2. 샤드 간 데이터 분포가 균등하지 못하여 어떤 샤드에 할당된 공간 소모가 다른 샤드에 비해 빨리 진행될 때
            
            → 샤드 키를 계산하는 함수 변경, 데이터를 재배치 해야
            
        - 유명인사 문제
        - 조인과 비정규화
            - 여러 샤드에 걸친 데이터를 조인하기가 힘들어짐
            
            ⇒  데이터베이스를 비정규화 → 하나의 테이블에서 질의가 수행될 수 있도록 함 
            

![image.png](image%202.png)

- 데이터베이스에 대한 부하를 줄이기 위해 RDBMS가 요구되지 않는 기능들은 NoSQL로 이전

---

<aside>
✅

웹 계층은 무상태 계층

모든 계층에 다중화 도입

가능한 한 많은 데이터를 캐시하도록

여러 데이터 센터를 지원

정적 컨텐츠는 CDN을 통해 서비스하도록

데이터 계층은 샤딩을 통해 그 규모를 확장

각 계층은 독립적 서비스로 분할

시스템을 지속적으로 모니터링, 자동화 도구들을 활용

</aside>

# 4장. 처리율 제한 장치의 설계

> **클라이언트or서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치**
> 
- 클라이언트의 요청 횟수 제한
- API에 처리율 제한 장치를 두면 좋은 점
    - DoS 공격 방지 가능
    - 추가 요청에 대한 처리를 제한 → 비용 절감
    - 서버 과부하 막음

---

## 1단계. 문제 이해 및 설계 범위 확정

- ***요구사항***
    - *설정된 처리율을 초과하는 요청은 정확하게 제한함*
    - ***낮은 응답시간** : 이 처리율 제한 장치는 HTTP 응답 시간에 나쁜 영향을 주어서는 곤란하다*
    - *가능한 한 적은 메모리를 사용해야*
    - ***분산형 처리율 제한** : 하나의 처리율 제한 장치를 여러 서버나 프로세스에서 공유할 수 있어야 함*
    - ***예외 처리** : 요청이 제한되었을 때 그 사실을 사용자에게 분명하게 보어주어야 함*
    - ***높은 결함 감내성** : 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어서는 안됨*

---

## 2단계. 개략적 설계안 제시 및 동의 구하기

### **처리율 제한 장치는 어디에 둘 것인가?**

1. 클라이언트 측 : 안정적으로 처리율 제한 X, 클라이언트 요청은 쉽게 위변조 가능
2. 서버 측 : API 서버/처리율 제한 미들웨어

⇒ 클라이언트/API서버 처리율 제한 장치 : API 서버로 전송됨 

⇒ 미들웨어 : HTTP 상태코드 429(Too many requests) 반환 

<aside>
✅

**클라우드 마이크로서비스의 경우**

⇒ 보통 **`API 게이트웨이**(=처리율 제한을 지원하는 미들웨어)`에 구현됨

> API gateway=처리율 제한, SSL 종단, 사용자 인증, IP 허용목록 관리 등을 지원하는 완전 위탁관리형 서비스. 
클라우드 업체가 유지 보수를 담당하는 서비스
> 
</aside>

**✔️ 처리율 제한 기능을 설계할 때 고려해야 할 점** 

- 현재 사용하는 프로그래밍 언어가 서버 측 구현을 지원하기 충분할 정도로 효율이 높은지 확인
- 필요에 맞는 `처리율 제한 알고리즘`을 찾아라
- 만약 설계가 마이크로서비스에 기반 → 사용자 인증이나 IP 허용목록 관리 등을 처리하기 위해 API 게이트웨이를 이미 설계에 포함시켰다면 → 처리율 제한 기능 또한 게이트웨이에 포함시켜야 할 수도..

### **처리율 제한 알고리즘**

1. **토큰 버킷 알고리즘**
    - 토큰 버킷=지정된 용량을 갖는 컨테이너
    - 버킷에는 사전 설정된 양의 토큰이 주기적으로 채워짐. 토큰이 꽉 찬 버킷에는 더 이상의 토큰은 추가되지 X
    - 버킷이 가득 차면 추가로 공급된 토큰은 버려진다 (overflow)
    - 각 요청은 처리될 때마다 하나의 토큰 사용
        - 충분한 토큰O → 버킷에서 토큰 하나를 꺼낸 후 요청을 시스템에 전달
        - 충분한 토큰X → 해당 요청은 버려짐(dropped)
    
    ![토큰 공급률=분당 4](image.png)
    
    토큰 공급률=분당 4
    
    - 토큰 공급률=초당 몇 개의 토큰이 버킷에 공급되는가
    - 통상적으로 API엔드포인트마다 별도의 버킷을 둔다
    - IP 주소별로 처리율 제한을 적용해야 한다면 IP 주소마다 버킷을 하나씩 할당해야 함
    - 짧은 시간에 집중되는 트래픽 처리가능
    ( ∵ 버킷에 남은 토큰이 있기는 하지만 요청은 시스템에 전달될 것)

**b. 누출 버킷 알고리즘**

- 요청 처리율이 항상 고정되어 있음
- FIFO 큐로 구현
- 요청이 도착하면 큐가 가득 차 있는지 본다 → 빈자리가 있는 경우 큐에 요청 추가
- 큐가 가득 차 있는 경우 새 요청은 버림
- 지정된 시간마다 큐에서 요청을 꺼내어 처리

![image.png](image%201.png)

- 인자
    - 버킷 크기 : 큐 사이즈와 같은 값. 큐에는 처리될 항목들이 보관됨
    - 처리율 : 지정된 시간당 몇 개의 항목을 처리할지
- 메모리 사용량 측면에서 효율적
- 단시간에 많은 트래픽 몰림 → 요청들을 제때 처리하지 못하면 최신 요청들은 버려짐

**c. 고정 윈도 카운터 알고리즘**

- 타임라인을 고정된 간격의 윈도로 나눔 → 각 윈도마다 카운터를 붙임
- 요청이 접수될 때마다 이 카운터의 값은 1씩 증가
- 카운터의 값이 사전에 설정된 임곗값에 도달 → 새로운 요청은 새 윈도가 열릴때까지 버려짐

![image.png](image%202.png)

- 윈도의 경계 부근 에 순간적으로 많은 트래픽 → 윈도에 할당된 양보다 더 많은 요청이 처리될 수 있음

**d. 이동 윈도 로깅 알고리즘**

- 요청의 타임스탬프 추적 : 타임스탬프 데이터는 레디스/정렬 집합 같은 캐시에 보관
- 새 요청 → 만료된 타임스탬프 제거
- 새 요청의 타임스탬프를 로그에 추가
- 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달

![image.png](image%203.png)

- 어느 순간의 윈도를 보더라도, 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다
- 거부된 요청의 타임스탬프도 보관 → 다량의 메모리를 사용한다는 단점

**e. 이동 윈도 카운터 알고리즘**

- 고정 윈도 카운터 알고리즘 + 이동 윈도 로깅 알고리즘
- 이전 시간대의 평균 처리율에 따라 현재 윈도 상태 계산 → 짧은 시간에 몰리는 트래픽에 잘 대응
- 메모리 효율 좋음

### 개략적인 아키텍처

> 얼마나 많은 요청이 접수되었는지 추적할 수 있는 카운터를 추적 대상별로 두고 이 카운터의 값이 어떤 한도를 넘어서면 한도를 넘어 도착한 요청은 거부
> 
- 카운터의 보관?
    
    ⇒ **캐시** 
    
    - 메모리상에서 동작해서 빠르고, 시간에 기반한 만료 정책 지원
    - Redis : 처리율 제한 장치 구현 시, 자주 사용되는 메모리 기반 저장장치로서 `INCR`, `EXPIRE`의 두 가지 명령어 지원
- 동작원리
    1. 클라이언트 → 처리율 제한 미들웨어에게 요청을 보냄
    2. 처리율 제한 미들웨어 : 레디스의 지정 버킷에서 카운터를 가져와서 한도에 도달했는지 아닌지를 검사 
        - 한도 도달 → 요청 거부
        - 한도 도달 X → 요청은 API서버로 전달됨 & 미들웨어는 카운터의 값을 증가시킨 후 다시 레디스에 저장

---

## 3단계. 상세 설계

**✔️처리율 제한 규칙** : 보통 설정파일 형태로 디스크에 저장됨 

**✔️ 처리율 한도 초과 트래픽의 처리**

- 한도 제한에 걸린 메시지를 나중에 처리하기 위해 큐에 보관 가능
- 처리율 제한 장치가 사용하는 HTTP 헤더
    - `X-Ratelimit-Remaining`: 위도 내에 남은 처리 가능 요청의 수
    - `X-Ratelimit-Limit` : 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
    - `X-Ratelimit-Retry-After` : 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림
    
    ⇒ HTTP 헤더를 통해 클라이언트는 자기 요청이 처리율 제한에 걸리고 있는지 등을 감지 가능
    

**✔️ 상세 설계**

![image.png](image%204.png)

- 처리율 제한 규칙 = 디스크에 보관, 작업 프로세스는 수시로 규칙을 디스크에서 읽어 캐시에 저장
- 처리율 제한 미들웨어는 제한 규칙을 캐시에서 가져옴
    
    카운터/마지막 요청의 타임스탬프 → 레디스 캐시에서 가져옴 
    
    - 해당 요청이 처리율 제한에 걸리지X ⇒ API서버로 보냄
    - 해당 요청이 처리율 제한에 걸림 ⇒ 429 too many requests 에러 (⇒ 메시지 큐에 해당 요청 보관)

**✔️ 분산 환경에서의 처리율 제한 장치의 구현**

- 여러 대의 서버/병렬 스레드에서 적용되도록 하려면
    
    ➡️ `경쟁 조건`/`동기화` 해결해야
    

1. **`경쟁 조건`**
    
    ![image.png](image%205.png)
    
    - 가장 잘 알려진 해결책 : **`락(lock)`**
        - 시스템의 성능을 상당히 떨어뜨린다.
    
    **✅ 루아 스크립트, 정렬집합 이라 불리는 레디스 자료구조 쓰는 방법**
    

b. **`동기화 이슈`**

- 처리율 제한 장치 서버를 여러 대 두게 되면 동기화가 필요해짐
- 웹 계층은 무상태이므로 클라이언트는 요청을 각기 다른 제한 장치로 보내게 될수 있음
    
    → 이 때 동기화를 하지 않으면 제한 장치 1은 클라이언트 2에 대해서 아무것도 모르므로 처리율 제한을 올바르게 수행할 수 없다
    

✔️ 고정 세션 활용 (클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보낼 수 있도록 함)

⇒ 규모면에서 확장 가능X, 유연X

 **✅ 레디스 같은 중앙 집중형 데이터 저장소 사용**

![image.png](image%206.png)

**c. 성능 최적화**

- **데이터센터 지원 문제**
    - 데이터센터에서 멀리 떨어진 사용자를 지원하려다보면 지연시간이 증가할 수 밖에 없음
    
    ⇒ 세계 곳곳에 에지 서버를 심어놓음 → 사용자의 트래픽을 가장 가까운 에지서버로 전달하여 지연시간을 줄임
    
- 제한 장치 간에 **데이터를 동기화**할 때 **최종 일관성 모델**을 사용하는 것

**d. 모니터링**

## 4단계. 마무리

- hard OR soft 처리율 제한
    - hard : 요청 개수는 임계치를 절대 넘어설 수 X
    - soft : 요청 개수는 잠시 동안은 임계치를 넘어설 수 O
- 다양한 계층에서의 처리율 제한
    - 여태까지는 애플리케이션 계층에서의 처리율 제한에 대해서만 살펴봄
    - 다른 계층에서도 처리율 제한 가능
- **처리율 제한을 회피하는 방법**
    - 클라이언트 측 캐시 사용 → API 호출 횟수를 줄임
    - 짧은 시간 동안 너무 많은 메시지를 보내지 않도록 함
    - 예외/에러 처리 코드 도입 → 우아하게 복구할 수 있도록
    - 재시도 로직 구현 시 충분한 백오프 시간