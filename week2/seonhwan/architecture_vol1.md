# 1장 : 사용자 수에 따른 규모 확장성

## 단일 서버
![[Pasted image 20251111195549.png]]
기본적인 흐름
- 도메인 이름을 이용해 웹사이트 접속 (DNS 이용)
- IP 주소로 HTTP 요청
- HTML, JSON 형태의 응답을 반환
## 데이터베이스
![[Pasted image 20251111195812.png]]
### 데이터베이스 종류
- 관계형 데이터 베이스(RDBMS)
	- 자료를 테이블과 열, 칼럼으로 표현한다.
	- 여러 테이블에 있는 데이터를 관계에 따라 조인하여 합칠 수 있다.
	- MySQL
	- PostgreSQL
- 비관계형 데이터베이스
	- 비정형 데이터를 저장한다.
	- 조인을 지원하지 않는다
	- 대규모 읽기/쓰기, 낮은 응답 지연시간, 비정형 데이터를 사용하는 경우 사용하면 좋다
	- NoSQL
		- 키-값 저장소
		- 그래프 저장소
		- 칼럼 저장소
		- 문서 저장소
## 수직적 규모 확장 vs 수평적 규모 확장
스케일 업 (수직적 규모 확장)
- 서버에 고사양 자원을 추가하는 행위를 말한다.
- CPU, 메모리를 무한대로 늘릴 수 없기 때문에 한계가 존재한다.
- 자동복구, 다중화 방안을 제시하지 않아 서버 장애 발생 시 완전히 중단된다.
스케일 아웃 (수평적 규모 확장)
- 더 많은 서버를 추가하여 성능을 개선한다.
- 대규모 애플리케이션은 스케일 아웃이 더 적절하다.
### 로드 밸런서
![[Pasted image 20251111200418.png]]
로드 밸런서는 여러 서버에 요청을 분산시켜 트래픽 과부하를 방지하기 위해 사용한다.
#### 동작 방식
- 클라이언트는 공개 IP 주소로 요청
- 로드밸런서가 요청 분산
- 만약 서버 1이 다운되면 트래픽을 모두 서버 2로 전송하여 장애 방지를 한다.
- 만약 서버 2대로 트래픽을 감당할 수 없다면 새로운 서버를 추가한다. -> 자동 분산
#### 데이터베이스 다중화
![[Pasted image 20251111200918.png]]
- 데이터베이스는 주-부 관계를 설정하고 쓰기는 주 데이터베이스에, 읽기 연산은 부 데이터베이스에 요청
- 여기서 저장된 주 데이터베이스의 사본이 부 데이터베이스 서버에 저장
- 보통은 쓰기 연산보다 읽기 연산이 더 많기 때문에 부 데이터베이스 서버를 여러대 두는 방식을 사용
- 성능 향상
	- 읽기 연산을 병렬로 처리하여 더 성능이 좋아진다.
- 안정성
	- 데이터베이스 일부가 망가져도 데이터는 보존된다.
- 가용성
	- 여러 지역에 복제하여 장애가 발생하여도 다른 데이터를 가져와 서비스할 수 있다.
만약 장애가 발생하면 다음과 같은 방식으로 해결한다
- 부 서버 다운
	- 부 서버가 한 대인 경우
		- 부 서버 다운시 읽기 연산이 일시적으로 주 데이터베이스로 전달된다.
		- 새로운 부 데이터베이스가 장애를 대처
	- 부 서버가 여러대인 경우
		- 나머지 다른 부서버들로 읽기 연산이 분산된다.
		- 새로운 부 데이터베이스가 장애를 대처한다.
- 주 서버 다운
	- 부 서버가 한 대인 경우
		- 부 서버가 주서버가 되며, 새로운 부 서버가 추가된다.

## 캐시
캐시는 자주 참조되는 데이터를 메모리 안에 두고 뒤이은 요청이 빨리 처리될 수 있도록 하는 저장소
![[Pasted image 20251111201840.png]]
읽기 주도형 캐시 전략
- 캐시가 존재하는 경우 : 캐시에서 데이터 읽기
- 존재하지 않는 경우 : 데이터베이스에서 캐시에 저장 -> 데이터 반환
#### 유의사항
- 캐시는 데이터 갱신이 자주 일어나지 않지만 참조가 빈번히 일어나는 경우 고려해야한다.
- 영속적으로 보관할 데이터는 캐시에 두지 않는다.
- TTL을 적절히 설정하는 것이 중요하다.
	- 만약 만료 정책이 없으면 캐시에 계속 남아있어 메모리 낭비가 심해진다.
	- 만료 시간이 짧으면 데이터베이스를 너무 자주 읽게 된다.
	- 너무 길면 원본과 차이 날 가능성이 높아지게 된다.
- 데이터베이스의 원본과 일관성을 유지해야한다.
	- 원본 갱신 연산과 캐시 갱신 연산이 단일 트랜잭션으로 처리되어야 한다.
- 장애 대응을 해야한다.
	- 캐시 서버가 한대인 경우 단일 장애 지점이 될 수 있다.
	- 단일 장애 지점 : 특정 지점에서 장애 발생 시 전체 시스템 동작 중단되는 현상
	- 따라서 여러 지역에 걸쳐 캐시를 분산시켜야 한다.
- 캐시 메모리를 너무 작게 잡으면 안된다. -> 캐시메모리 과할당 사용
- 데이터 방출 정책에 대해 생각해야한다.
	- LRU : 최근에 사용하지 않은 항목 제거
	- LFU : 사용 빈도가 낮은 항목 제거
	- FIFO : 먼저 들어온 항목 제거
## CDN
CDN은 정적 콘텐츠를 전송하는 데 쓰이는 지리적으로 분산된 서버의 네트워크이다.
사용자의 위치에 따라 가장 가까운 서버에서 제공한다
- 동적 컨텐츠 캐싱
	- 요청 경로, 질의 문자열, 쿠키, 요청 헤더 등에 기반하여 HTML 페이지 캐시
![[Pasted image 20251111202610.png]]
### 고려사항
- 비용
	- CDN에 들어가고 나가는 데이터 양에 따라 요금을 낸다. 자주 사용하지 않는 콘텐츠는 빼는 것이 좋다.
- TTL 설정
	- 캐시와 마찬가지이다.
- 장애 대처 방안
	- CDN이 응답하지 않는 경우 직접 콘텐츠를 가져오도록 구성할 필요가 있다.
- 콘텐츠 무효화
	- 만료되지 않은 콘텐츠여도 CDN에서 제거할 수 있다.
![[Pasted image 20251111202932.png]]
- 정적 콘텐츠는 CDN을 통해 더 나은 성능을 보장한다.
- 캐시가 데이터베이스 부하를 줄인다.
## 무상태 웹 계층
- 웹 계층을 수평적으로 확장하기 위해 상태 정보를 제거하고 상태 정보는 데이터베이스에 보관을 한다.
![[Pasted image 20251111203145.png]]
- 그림을 보면 사용자 A는 세션 데이터가 서버 1에 존재하여 무조건 서버 1로 전송해야한다.
- 사용자 B, C도 마찬가지이다.
- 로드밸런서에서 고정 세션 기능을 사용할 수 있지만 이는 부담이 된다.
![[Pasted image 20251111203422.png]]
- 공유 저장소를 두고 사용자가 아무 웹 서버로 전송할 수 있도록 한다.
- 공유 저장소는 캐시, NoSQL에 저장할 수 있다.
## 데이터 센터
장애가 없는 상태에서는 가장 가까운 데이터 센터로 안내된다. -> 지리적 라우팅
- geoDNS : 사용자 위치에 따라 도메인 이름을 어떤 IP 주소로 변환할지 결정할 수 있도록 해주는 DNS 서비스
![[Pasted image 20251111203833.png]]
- 여기서 West에 장애가 발생하면 East로 트래픽이 전송되게 된다.
- 트래필 우회
	- 올바른 데이터센터로 전송하는 방법을 찾아야 한다.
- 데이터 동기화
	- 데이터 센터마다 별도의 데이터베이스를 사용하는 경우 데이터를 데이터 센터에 걸쳐 다중화를 하면 된다.
- 테스트, 배포
	- 사이트를 여러 위치에서 테스트해야한다.
## 메시지큐
- 메시지 큐는 보관된 메시지가 소비자가 꺼낼 때까지 안전하게 보관된다는 특성을 가지고 있는 비동기 통신을 지원하는 컴포넌트
- pub/sub 구조로 publisher가 메세지를 큐에 전송하고 subscriber는 메시지를 받아 그에 맞는 동작을 수행하게 된다.
- 이는 서버 간 결합이 느슨해져 규모 확장성이 보장되어야 하는 애플리케이션을 구성하기 좋다
- 생산자는 소비자가 다운되어있어도 메시지를 발행할 수 있고, 소비자는 생산자가 가용 상태가 아니여도 메시지를 수신할 수 있다.
- 오래걸리는 작업 (AI 답변, 이미지 생성 등) 시 유용하다
## 로그, 메트릭, 자동화
- 로그
	- 에러 로그 모니터링이 중요하다.
	- 로그를 단일 서비스로 모아주는 도구를 활용하면 편리하다.
- 메트릭
	- 현재 상태를 손쉽게 파악할 수 있다.
	- 호스트 단위 메트릭 : CPU, 메모리, 디스크 I/O
	- 종합 메트릭 : 데이터베이스 계층 성능, 캐시 성능
	- 핵심 비즈니스 메트릭 : 일별 능동 사용자, 수익, 재방문
- 자동화
	- CI, CD 등 자동 통합, 배포 서비스
![[Pasted image 20251111204559.png]]
## 데이터베이스 규모 확장
- 앞서 설명했던 것처럼 스케일 아웃이 더 적합하다.
- 샤딩
	- 대규모 데이터베이스를 샤드라는 단위로 분할하는 기술
	- 샤드에 보관되는 데이터는 중복되지 않는다
	![[Pasted image 20251111204738.png]]
	- 가장 중요한 것은 샤딩키
	- 데이터를 고르게 분할할 수 있도록 샤딩키를 잘 설정해야 한다.
	- 문제점
		- 재샤딩
			- 하나의 샤드로 부족한 경우
			- 샤드 할당된 공간 소모가 다른 샤드에 비해 빨리 진행되는 경우
			- 안정해시 기법을 활용하여 해결한다.
		- 유명인사 문제
			- 특정 샤드에 질의가 집중되어 과부하가 걸리는 문제
		- 조인과 비정규화
			- 샤드로 쪼개면 여러 샤드에 걸친 데이터를 조인하기 힘들다.
			- 이를 해결하기 위해 데이터베이스 비정규화 진행


# 4장 : 처리율 제한 장치의 설계
## 1단계 문제 이해 및 설계 범위 확정
- 설정된 처리율을 초과하는 요청을 정확히 계산
- HTTP 응답시간에 나쁜 영향을 주면 안된다.
- 가능한 적은 메모리 사용
- 하나의 처리율 제한 장치를 여러 서버가 공유할 수 있어야 한다.
- 요청 제한 시 그 사실을 사용자에게 보여줘야 한다.
- 장애가 생겨도 전체 시스템에 영향을 주어서는 안된다.
## 2단계 개략적 설계안 제시 및 동의 구하기
- 처리율 제한 장치의 위치
	- 클라이언트에 두면 위변조가 가능해 좋은 장소가 아니다.
	- 서버에 두기
	![[Pasted image 20251111210015.png]]
	- 미들웨어로 두기
	![[Pasted image 20251111210048.png]]
- 처리율 제한장치는 보통 API 게이트웨이에 구현된다.
	- API 게이트 웨이 : 처리율 제한, SSL 종단, 사용자 인증, IP 허용 목록 관리를 지원하는 서비스
- 적용될 수 있는 지침
	- 프로그래밍 언어가 서버 측 구현을 지원하기 충분할 정도로 효율이 높은가?
	- 사업 필요에 맞는 알고리즘 찾기
	- MSA에 기반하고 API 게이트웨이를 포함시킨 경우 처리율 제한 기능도 API 게이트웨이에 포함시켜야 할 수도 있다.
	- 충분한 인력이 없다면 API 게이트웨이를 쓰는게 좋다.
### 처리율 제한 알고리즘
#### 토큰 버킷 알고리즘
- 토큰 버킷은 지정된 용량을 갖는 컨테이너이며 사전 설정된 양의 토큰이 주기적으로 채워진다. 꽉 찬 경우 더이상 채워지지 않고 버려진다.
- 요청 처리 시 하나의 토큰 사용한다.
	- 토큰이 충분한 경우 : 버킷에서 토큰을 꺼내 시스템에 전달
	- 충분하지 않은 경우 : 버려진다.
	![[Pasted image 20251111210604.png]]
![[Pasted image 20251111210638.png]]
- 이는 2개의 인자를 받는다
	- 버킷 크기 : 담을 수 있는 토큰 최대 개수
	- 토큰 공급률 : 초당 몇개의 토큰이 공급되는지
- 보통 API 엔드포인트마다 별도의 버킷을 둔다.
- IP 주소별로 적용 시 주소마다 버킷을 할당한다.
- 장점
	- 구현이 쉽다
	- 메모리 사용 측면에서 효율적이다
	- 짧은 시간 집중되는 트래픽 처리가 가능하다 -> 토큰만 있으면 된다
- 단점
	- 버킷 크기와 토큰 공급률을 적절히 튜닝하는 것이 어렵다
#### 누출 버킷 알고리즘
- 위와 다르게 요청 처리율이 고정되어 있다.
- FIFO로 구현한다
- 동작 원리
	- 요청 도착 시 큐 확인
	- 빈자리가 있으면 큐에 추가, 가득찬 경우 새 요청 버린다
	- 지정된 시간마다 큐에서 요청을 꺼내 처리한다
	![[Pasted image 20251111211150.png]]
- 인자
	- 버킷 크기 : 큐 사이즈와 같은 값
	- 처리율 : 지정된 시간당 몇 개의 항목을 처리할지 지정하는 값
- 장점
	- 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적이다
	- 고정된 처리율을 갖고 있어 안정적 출력이 필요한 경우 적합하다
- 단점
	- 단시간 트래픽이 몰리면 최신 요청들이 버려지게 된다
	- 토큰 버킷과 마찬가지로 인자 두개를 올바르게 튜닝하기 까다롭다
#### 고정 윈도 카운터 알고리즘
- 작동 방식
	- 타임라인ㅇ를 고정된 가격의 윈도로 나누고 윈도마다 카운터 붙이기
	- 요청 접수 시 카운터 1 증가
	- 임계치에 도달 시 새 윈도가 열릴 때까지 버려진다
- 윈도의 경계 부근에 순간적으로 많은 트래픽이 집중되면 할당된 양보다 더 많은 요청이 처리될 수 있다
- 장점
	- 메모리 효율이 좋다
	- 이해하기 쉽다
	- 윈도 닫히는 시점에 카운털르 초기화하는 방식은 특정 트래픽 패턴을 처리하기 적합하다
- 단점
	- 윈도 경계 부근에 일시적으로 많은 트래픽이 몰리면 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리한다
#### 이동 윈도 로깅 알고리즘
- 고정 윈도 카운터 알고리즘의 단점을 해결한 것
- 작동 방식
	- 요청 타임스탬프를 추적한다. 보통 레디스의 정렬 집합같은 캐시에 저장한다
	- 만료된 타임스탬프는 제거한다
	- 새 요청의 타임스탬프를 로그에 추가한다
	- 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다. 아닌 경우 처리를 거부한다
	![[Pasted image 20251111213809.png]]
- 장점
	- 항상 허용되는 요청의 개수가 시스템 처리율 한도를 넘지 않는다
- 단점
	- 거부된 요청의 타임스탬프도 보관하여 다량의 메모리를 사용한다
#### 이동 윈도 카운터 알고리즘
- 고정윈도 카운터 + 이동 윈도 로깅
![[Pasted image 20251111214207.png]]
- 현재 1분간 요청 수 + 직전 1분간 요청 수 x 이동 윈도와 직전 1분이 겹치는 비율
- 3 + 5 * 70% = 6.5개
- 여기서 제한 장치의 한도가 분당 7개로 설정되어있다고 하였으므로 현재 1분의 30% 시점에 도착한 신규 요청은 시스템으로 전달된다
- 장점
	- 짧은 시간에 몰리는 트래픽에도 잘 대응한다
	- 메모리 효율이 좋다
- 단점
	- 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태로 계산하여 다소 느슨하다. -> 그러나 실제로는 큰 문제 없다

### 개략적 아키텍처
카운터는 메모리상에 동작하는 캐시가 바람직하다
Redis가 자주 사용되며 INCR, EXPIRE 명령어를 지원한다
- INCR : 메모리에 저장된 카운터 값을 1 증가시킨다
- EXPIRE : TTL을 설정한다
![[Pasted image 20251111214753.png]]
- 클라이언트가 미들웨어에 요청을 보낸다
- 미들웨어가 레디스의 지정한 버킷에서 카운터를 가져와 한도에 도달했는지 검사한다
	- 한도 도달 시 요청 거부된다
	- 도달하지 않은 경우 API 서버로 전달된다. 이후 미들웨어가 카운터 값을 증가시켜 Redis에 저장한다
## 3단계 상세 설계
### 처리율 제한 규칙
설정파일 형태로 저장된 규칙을 확인한다
![[Pasted image 20251111215054.png]]
사진을 보면 마케팅 메시지가 최대 5개로 제한되어있다
### 처리율 한도 초과 트래픽 처리
- 한도 제한에 걸리면 429 응답을 보낸다. 경우에 따라서는 큐에 저장하여 나중에 처리할 수 있다
- HTTP 헤더
	- X-Ratelimit-Remaining : 윈도에 남은 처리 가능 요청 수
	- X-Ratelimit-Limit : 매 윈도마다 클라이언트가 전송할 수 있는 요청 수
	- X-Ratelimit-Retry-After : 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림
- 429 응답을 보통 X-Ratelimit-Retry-After와 함께 반환한다
### 상세 설계
![[Pasted image 20251111215327.png]]
- 클라이언트가 요청을 보내면 미들웨어에 도달한다
- 미들웨어가 제한규칙을 캐시에서 가져오고 마지막 요청의 타임스탬프를 레디스 캐시에서 가져온다.
	- 해당 요청이 처리율 제한에 걸리지 않으면 API 서버로 보낸다
	- 처리율 제한이 걸린 경우 429를 클라이언트에 보낸다. 여기서 요청을 버릴 수도 있고 메시지 큐에 보관할 수도 있다
### 분산 환경에서 처리율 제한 장치 구현
- 경쟁 조건
	- 레디스에서 카운터 읽기
	- counter + 1이 임계치 넘는지 확인
	- 넘지 않으면 값 1 증가
![[Pasted image 20251111215742.png]]
	- 병렬로 실행되는 과정에서 counter의 예상값이 5지만 4가 되는 문제가 생길 수 있다
	- 락으로 해결할 수 있지만 성능이 떨어진다
	- 루아 스크립트와 정렬집합으로 해결할 수 있다
- 동기화 이슈
	- 수백만 사용자를 지원하기 위해 처리율 제한 장치 서버를 여러 대 둘 수 있다
	- 무상태 웹계층에서 클라이언트 1이 처리율 제한장치 1로 보내다가 2로 바꾸게 되면 올바르게 수행될 수 없다
	![[Pasted image 20251111220808.png]]
	- 고정세션
		- 요청이 항상 같은 처리율 장치로 보낼 수 있도록 하는 것
		- 확장가능하지 않고 유연하지 않아 추천하지 않는다
	- 레디스를 사용해 해결한다
	![[Pasted image 20251111220903.png]]
## 4단계 : 마무리
- 경성 처리율 제한
	- 요청의 개수가 임계치를 넘을 수 없다
- 연성 처리율 제한
	- 요청의 개수가 임계치를 일시적으로 넘을 수 있다
- Iptables를 사용하여 IP 주소에 처리율 제한을 적용하는 것이 가능하다
- 처리율 제한 회피 방법
	- 클라이언트 측 캐시를 사용하여 API 호출 횟수를 줄인다
	- 짧은 시간동안 너무 많은 메시지를 보내지 않도록 한다
	- 예외나 에러 처리를 통해 복구될 수 있도록 한다
	- 재시도 로직을 구현할 때 충분한 백오프 시간을 둔다
