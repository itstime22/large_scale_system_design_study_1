# 5장 : 안정 해시 설계
## 해시 키 재배치 문제
- 해시는 mod 연산으로 서버 인덱스를 결정한다
![](./image/Pasted%20image%2020251117185927.png)
- 만약 그림에서 4개의 서버 중 하나의 서버에 장애가 발생하거나 추가되면 서버 풀의 크기가 변하며 키에 대한 해시 값은 변하지 않지만 서버 인덱스 값이 달라진다.
- 이런 상황이 생기면 계속 재배치를 해야하기 때문에 좋지 않다
## 안정 해시
- 안정해시는 해시 테이블 크기가 조정될 때 평균적으로 k/n개의 키만 재배치하는 해시 기술을 말한다.
- k는 키의 개수, n은 슬롯의 개수
### 해시 서버
![](./image/Pasted%20image%2020251117190412.png)
- 그림에서 해시 서버는 해시링의 특정 위치에 배치한다
- 해시 키 또한 해시링의 특정 위치에 배치한다
- 어떤 키가 저장되는 서버는 키의 위치로부터 시계방향으로 링을 탐색해 만나는 첫번 째 서버이다.
	- k0 -> s0, k1 -> s1, k2 -> s2, k3 -> s3
- s0 앞에 s4가 새로 추가되면 k0->s4로 변경되며 나머지 키는 재배치되지 않는다
- s1이 삭제된다고 가정하면 k1->s2로 재배치되며 나머지 키는 영향이 없다
### 기본 구현법의 두 가지 문제
- 서버가 추가되거나 삭제되는 상황을 감안하면 파티션의 크기를 균등하게 유지하는 것이 불가능하다
- 키의 균등 분포를 달성하기 어렵다
### 가상 노드
- 실제 노드 또는 서버를 가리키는 노드로 하나의 서버는 링 위에 여러 가상 노드를 가질 수 있다
- 각 서버가 여러 파티션을 관리한다
![](./image/Pasted%20image%2020251117191115.png)
- 시스템 요구사항에 맞게 가상 노드 개수를 적절히 조정해야한다


# 6장 : 키-값 저장소 설계
## 단일 서버 키-값 저장소
- 키-값 쌍을 전부 메모리에 해시 테이블로 저장하면 속도가 빠르지만 모든 데이터를 메모리에 두기에는 한계가 존재한다
	- 데이터 압축
	- 자주 쓰이는 데이터만 메모리에 두고 나머지를 디스크에 저장
## 분산 키-값 저장소
### CAP 정리
- 일관성
	- 어떤 노드에 접속했느냐에 관계없이 언제나 같은 데이터를 보게 되어야 한다
- 가용성
	- 일부 노드에 장애가 발생하더라도 항상 응답을 받을 수 있어야 한다
- 파티션 감내
	- 파티션은 두 노드 사이에 통신 장애가 발생하였음을 의미한다
	- 네트워크에 파티션이 생겨도 시스템이 계속 동작해야한다
![](./image/Pasted%20image%2020251117191836.png)
#### 실세계의 분산 시스템
- 분산 시스템에서 파티션 문제는 피할 수 없다
![](./image/Pasted%20image%2020251117192058.png)
- CP 시스템
	- 세 서버 사이에 생길 수 있는 불일치 문제를 피하기 위해 n1, n2 쓰기 연산을 중단시켜야 한다
	- 가용성이 깨지게 된다
- AP 시스템
	- 낡은 데이터를 반환할 위험이 있더라도 읽기 연산을 계속해야한다
	- n1, n2는 계속 쓰기 연산을 허용하며, 파티션 문제가 해결되면 뒤 새 데이터를 n3에 전송한다
### 시스템 컴포넌트
- 데이터 파티션
	- 따져봐야할 문제
		- 데이터를 여러 서버에 고르게 분산할 수 있는가?
		- 노드가 추가되거나 삭제될 때 데이터의 이동을 최소화할 수 있는가?
	- 안정해시 사용
		- 규모 확장 자동화 : 시스템 부하에 따라 서버가 자동으로 추가되거나 삭제되도록 만들 수 있다
		- 다양성 : 각 서버의 용량에 맞게 가상 노드의 수를 조정할 수 있다
- 데이터 다중화
	- 데이터를 N개의 서버에 비동기적으로 다중화
	- 어떤 키를 시계방향으로 순회하며 만나는 첫 N개 서버에 데이터 사본을 보관한다
	- 위 경우 N개의 노드가 대응될 실제 물리 서버의 개수가 N보다 작아질 수 있다. 이 때 같은 물리 서버를 중복선택하지 않도록 해야한다
- 데이터 일관성
	- 여러 노드에 다중화된 데이터가 적절히 동기화되어야 한다
	- 정족수 합의 프로토콜을 사용하면 읽기/쓰기 연산 모두에 일관성을 보장할 수 있다
	- N = 사본 개수
	- W = 쓰기 연산에 대한 정족수
	- R = 읽기 연산에 대한 정족수
	![](./image/Pasted%20image%2020251117193315.png)
	- 여기서 w=1인 경우 쓰기 연산을 성공했다고 판단하기 위해 중재자가 최소 한 대 서버로부터 쓰기 성공 응답을 받아야한다는 의미이다
	- 중재자는 클라이언트와 노드 사이에서 프록시 역할을 한다
	- W = 1, R = 1인 경우 응답속도가 빠르다. 1보다 큰 경우는 데이터 일관성의 수준이 향상되지만 중재자 응답속도는 느려진다
	- W + R > N인 경우 강한 일관성이 보장된다
#### 일관성 모델
- 강한 일관성
	- 모든 읽기 연산이 가장 최근에 갱신된 결과를 반환한다
	- 고가용성 시스템에 적합하지 않다
- 약한 일관성
	- 읽기 연산이 최근에 갱신된 결과를 반환하지 못할 수 있다
- 결과적 일관성
	- 갱신 결과가 결국 모든 사본에 반영되는 모델
	- 쓰기 연산이 병렬적으로 발생 시 시스템에 저장된 값의 일관성이 깨질 수 있다
	- 다이나모, 카산드라
#### 비일관성 해소 기법 : 데이터 버저닝
- 데이터 다중화 시 가용성이 높아지지만 일관성이 깨질 수 있다
- 버저닝
	- 데이터 변경 시마다 해당 데이터의 새로운 버전을 만드는 것
	- 각 버전의 데이터는 변경이 불가능하다
- 벡터 시계
	- [서버, 버전]의 순서쌍을 데이터에 붙인것이다
	- 어떤 버전이 선행인지, 후행인지, 다른 버전과 충돌이 있는지 판별하는데 쓰인다
	- D([S1, v1], [S2, v2], ..., [Sn, vn])
		- D는 데이터
		- vi는 버전 카운터
		- Si는 서버 번호
	- [Si, vi]가 있으면 vi를 증가시킨다
	- 그렇지 않으면 새 항목 [Si, 1]을 만든다
	![](./image/Pasted%20image%2020251117194857.png)
	- 문제점
		- 충돌 감지 및 해소 로직이 클라이언트에 들어가 클라이언트 구현이 복잡해진다
		- [서버:버전]의 순서쌍 개수가 굉장히 빨리 늘어난다 -> 길이에 어떤 임계치를 설정하고 임계치 이상으로 길어지면 오래된 순서쌍을 벡터 시계에서 제거
#### 장애 감지
- 노드 사이에 멀티캐스팅 채널을 구축하여 서버 장애를 감지한다
- 가십 프로토콜
	- 분산형 장애 감지 솔루션
	- 동작 원리
		- 각 노드가 맴버십 목록을 유지하며 맴버십 목록은 각 멤버 ID와 박동 카운터쌍 목록이다
		- 각 노드가 주기적으로 박동 카운터를 증가시킨다
		- 무작위로 선정된 노드들에게 주기적으로 자기 박동 카운터 목록을 보낸다
		- 박동카운터 목록을 받은 노드는 맴버십 목록을 최신 값으로 갱신한다
		- 특정 멤버의 박동 카운터 값이 지정된 시간동안 갱신되지 않으면 해당 멤버는 장애 상태인 것으로 간주한다
		![](./image/Pasted%20image%2020251117210851.png)
#### 일시적 장애 처리
- 엄격한 정족수 -> 읽기, 쓰기 연산 금지
- 느슨한 정족수
	- 쓰기 연산을 수행할 W개의 건강한 서버와 읽기 연산을 수행할 R개의 건강한 서버를 해시 링에서 고른다
	- 장애 상태인 서버로 가는 요청을 다른 서버가 잠시 맡아 처리한다
	- 변경사항을 해당 서버가 복구되었을 때 일괄 반영하여 일관성을 보존한다
	![](./image/Pasted%20image%2020251117211130.png)
#### 영구 장애 처리
- 반-엔트로피 프로토콜
	- 사본들을 비교하여 최신 버전으로 갱신하는 과정
	- 일관성이 망가진 상태를 탐지하고 전송 데이터의 양을 줄이기 위해 머클 트리 사용
	- 머클 트리(해시 트리) : 각 노드에 그 자식 노드들에 보관된 값의 해시, 또는 자식 노드들의 레이블로부터 계산된 해시값을 레이블로 붙여두는 트리
	- 머클트리 예제
		- 키 공간을 버킷으로 나눈다
		- 버킷에 포함된 각각의 키에 균등 분포 해시함수를 적용하여 해시 값을 계산한다
		- 버킷별로 해시값을 계산한 후, 해당 해시 값을 레이블로 갖는 노드를 만든다
		- 자식 노드의 레이블로부터 새로운 해시 값을 계산하여, 이진 트리를 상향식으로 구성한다
