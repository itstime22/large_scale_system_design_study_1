- 구글 드라이브: 파일 저장 및 동기화 서비스. 파일 클라우드에 보관 가능. 공유 가능.

# 1단계: 문제 이해 및 설계 범위 확정

- 기능적 요구사항
    - 파일 추가
    - 파일 다운로드
    - 여러 단말에 파일 동기화
    - 파일 갱신 이력 조회
    - 파일 공유
    - 파일 편집 및 삭제 및 새롭게 공유되었을 때 알림 표시
- 비-기능적 요구사항
    - 안정성
    - 빠른 동기화 속도
    - 네트워크 대역폭
    - 규모 확장성
    - 높은 가용성
- 개략적 추정치
    - 가입 사용자는 5천만 명
    - 일간 능동 사용자(DAU)는 1천만 명
    - 모든 사용자에게 10GB의 무료 저장공간을 할당
    - 매일 각 사용자가 평균 2개의 파일을 업로드하고 파일의 평균 크기는 500KB
    - 읽기:쓰기 비율은 1:1
    - 필요한 총 저장공간은 500페타바이트
    - 업로드 API QPS는 약 240, 최대 QPS는 480입니다.

# 2단계: 개략적 설계안 제시 및 동의 구하기

### 한 대 서버의 제약 극복

- 업로드되는 파일이 많아지면 결국 파일 시스템은 가득 차게 된다. 이를 해결하기 위해 데이터를 샤딩하여 여러 서버에 나누어 저장할 수 있다.
- 예를 들어 user_id를 기준으로 샤딩을 적용한다.
- 또한 데이터 손실을 막고 가용성을 보장하기 위해 아마존 S3와 같은 객체 저장소 서비스를 사용한다.
- S3는 동일 지역 내 다중화뿐만 아니라 여러 지역에 걸친 다중화를 지원하여 데이터 손실을 막고 가용성을 최대한 보장할 수 있다.

### 개선된 설계안

- 시스템의 가용성과 확장성을 위해 각 컴포넌트를 분리한다.
- 로드밸런서는 네트워크 트래픽을 분산하고 특정 웹 서버 장애 시 우회 경로를 제공한다.
- 웹 서버는 로드밸런서 추가 이후 더 쉽게 추가할 수 있어 트래픽 폭증에 대응 가능하다
- 메타데이터 데이터베이스는 파일 저장 서버에서 분리하여 SPOF를 회피하고 다중화 및 샤딩 정책을 적용한다.
- 파일 저장소는 S3를 사용하며 가용성과 무손실을 위해 두 개 이상의 지역에 데이터를 다중화한다.

### 동기화 충돌

- 두 명 이상의 사용자가 같은 파일이나 폴더를 동시에 업데이트하려고 할 때 발생한다.
- 이 시스템에서는 먼저 처리되는 변경은 성공한 것으로 보고, 나중에 처리되는 변경은 충돌이 발생한 것으로 표시하는 전략을 사용한다.
- 충돌이 발생하면 같은 파일의 두 가지 버전(로컬 사본과 서버의 최신 버전)이 존재하게 되며, 사용자는 두 파일을 하나로 합칠지 아니면 하나를 다른 파일로 대체할지 결정해야 한다.

# 3단계: 상세 설계

### 블록 저장소 서버

- 정기적으로 갱신되는 큰 파일은 업데이트마다 전체 파일을 서버로 보내면 대역폭 소모가 크다.
- 이를 최적화하기 위해 파일이 수정되면 전체 파일 대신 수정된 블록만 동기화하는 델타 동기화와, 블록 단위로 압축하여 데이터 크기를 줄이는 압축 전략을 사용한다.
- 블록 저장소 서버는 클라이언트가 보낸 파일을 블록 단위로 나누고, 압축 및 암호화 과정을 거쳐 클라우드 저장소로 전송하는 역할을 담당한다.

### 높은 일관성 요구사항

- 이 시스템은 강한 일관성 모델을 기본으로 지원해야 한다.
- 같은 파일이 단말이나 사용자에 따라 다르게 보이는 것은 허용되지 않는다.
- 따라서 메타데이터 캐시와 데이터베이스 계층에서도 강한 일관성을 보장해야 합니다.
- 관계형 데이터베이스는 ACID를 보장하므로 강한 일관성을 보장하기 쉽지만, NoSQL은 이를 기본 지원하지 않으므로 동기화 로직 내에 프로그램적으로 구현해야 한다.
    - 본 설계에서는 ACID를 지원하는 관계형 데이터베이스를 채택합니다.

### 메타데이터 데이터베이스

- 데이터베이스 스키마는 user(사용자 정보), device(단말 정보), namespace(사용자의 루트 디렉터리), file(파일 최신 정보), file_version(파일 갱신 이력), block(파일 블록 정보) 테이블로 구성된다.
- file_version 테이블의 레코드는 갱신 이력 훼손을 막기 위해 읽기 전용으로 관리한다.

### 업로드 절차

- 사용자가 파일을 업로드하면 두 개의 요청이 병렬적으로 전송된다.
    - 첫 번째는 파일 메타데이터를 추가하기 위한 것으로, 메타데이터를 DB에 저장하고 업로드 상태를 대기 중(pending)으로 변경한 뒤 알림 서비스에 통지한다.
    - 두 번째는 파일을 클라우드 저장소로 업로드하는 것으로, 블록 저장소 서버에서 파일을 블록 단위로 쪼개고 압축/암호화하여 S3에 전송한다.
- 업로드가 끝나면 S3는 완료 콜백을 API 서버로 보내고, 메타데이터 DB의 상태를 완료(uploaded)로 변경하며 알림 서비스에 업로드 완료를 통지한다.

### 다운로드 절차

- 파일 다운로드는 파일이 새로 추가되거나 편집되면 자동으로 시작된다.
- 클라이언트가 접속 중일 때는 알림 서비스가 변경 발생을 알리고, 접속 중이 아닐 때는 데이터가 캐시에 보관되었다가 접속 시점에 알림을 보낸다.
- 변경을 감지한 클라이언트는 API 서버를 통해 새 메타데이터를 가져온 뒤, 블록들을 다운로드하여 파일을 재구성한다.

### 알림 서비스

- 파일의 일관성 유지를 위해 파일 수정 사실을 다른 클라이언트에 알려 충돌 가능성을 줄입니다. 본 설계에서는 롱 폴링 방식을 사용한다.
- 롱 폴링은 채팅 서비스와 달리 양방향 통신이 필요 없고 알림 빈도가 높지 않은 본 시스템에 적합하다.
- 각 클라이언트는 알림 서버와 롱 폴링 연결을 유지하다가 특정 파일 변경 감지 시 연결을 끊고 새 메타데이터를 내려받은 후 다시 연결을 복원한다.

### 저장소 공간 절약

- 파일의 여러 버전을 보관하면 저장 용량이 빨리 소진될 수 있다.
- 이를 해결하기 위해 중복된 파일 블록을 해시 값을 비교하여 제거하는 중복 제거(de-dupe), 보관할 파일 버전 개수에 상한을 두거나 중요한 버전만 보관하는 지능적 백업 전략, 그리고 자주 쓰이지 않는 데이터를 저렴한 아마존 S3 글래시어 같은 아카이빙 저장소로 옮기는 방법을 사용한다.

### 장애 처리

- 장애는 대규모 시스템이라면 피할 수 없는 것으로 설계 시 반드시 고려해야 합니다.
- 로드밸런서에 장애가 발생할 경우 부 로드밸런서가 활성화되어 트래픽을 이어받아야 하며, 로드밸런서끼리는 보통 박동 신호를 주기적으로 보내서 상태를 모니터링한다.
- 블록 저장소 서버에 장애가 발생하였다면 다른 서버가 미완료 상태 또는 대기 상태인 작업을 이어받아야 한다.
- S3 버킷은 여러 지역에 다중화할 수 있으므로 클라우드 저장소 한 지역에서 장애가 발생했다면 다른 지역에서 파일을 가져오면 된다.
- API 서버들은 무상태 서버이므로 로드밸런서는 장애가 발생한 서버에 트래픽을 보내지 않음으로써 해당 서버를 격리한다.
- 메타데이터 캐시 서버도 다중화하여 한 노드에 장애가 생겨도 다른 노드에서 데이터를 가져올 수 있으며 장애 서버는 새 서버로 교체한다.
- 메타데이터 데이터베이스의 경우 주 데이터베이스 장애 시 부 데이터베이스 서버 중 하나를 주 서버로 바꾸고 새 부 서버를 추가하며, 부 데이터베이스 장애 시에는 다른 서버가 읽기 연산을 처리하도록 하고 장애 서버를 교체한다.
- 알림 서비스는 많은 사용자와 롱 폴링 연결을 유지하므로 한 대 서버에 장애가 발생하면 백만 명 이상의 사용자가 연결을 다시 만들어야 한다.
- 한 대 서버로 백만 개 이상의 접속을 유지하는 것은 가능하지만 동시에 시작하는 것은 불가능하므로 복구는 상대적으로 느릴 수 있다.
- 오프라인 사용자 백업 큐 또한 다중화해 두어야 하며 장애 발생 시 구독 중인 클라이언트들은 백업 큐로 구독 관계를 재설정해야 한다.